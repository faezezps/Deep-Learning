{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "vMuqtwz6HPFu",
    "outputId": "0eb92370-1fbe-442d-b7f9-713e86ee79dd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.layers import Flatten, Concatenate, Input , Embedding, LSTM, Dense, Dropout\n",
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "from keras import Sequential\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yc5KvFPbqjr1"
   },
   "source": [
    "Load IMDB dataset from keras.datasets.\n",
    "\n",
    "\"This is a dataset of 25,000 movies reviews from IMDB, labeled by sentiment (positive/negative).\" [[1]](https://keras.io/api/datasets/imdb/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "colab_type": "code",
    "id": "IhVWGXDoHXmQ",
    "outputId": "bba120bd-37c1-4396-9248-bcc1c0ba1258"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 25000 training samples, 25000 test samples\n",
      "---review---\n",
      "[0, 0, 365, 1234, 0, 1156, 354, 0, 0, 0, 0, 0, 1016, 0, 0, 356, 0, 0, 1349, 500, 746, 0, 200, 0, 4132, 0, 0, 0, 1117, 1831, 0, 0, 4831, 0, 0, 0, 4183, 0, 369, 0, 215, 1345, 143, 0, 0, 1838, 0, 1974, 0, 0, 0, 257, 0, 0, 486, 0, 0, 0, 0, 0, 271, 0, 196, 0, 949, 4121, 0, 0, 0, 0, 2212, 2436, 819, 0, 0, 0, 0, 180, 0, 227, 0, 0, 2494, 0, 0, 423, 0, 168, 0, 0, 0, 0, 0, 665, 0, 270, 0, 0, 0, 197, 0, 161, 0, 0, 0, 0, 0, 0, 419, 665, 0, 0, 0, 0, 0, 0, 2084, 0, 4773, 0, 0, 0, 1901]\n",
      "---label---\n",
      "1\n",
      "Maximum review length: 2697\n",
      "Minimum review length: 70\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocabulary_size, skip_top=127, oov_char= 00 )\n",
    "\n",
    "print('Loaded dataset with {} training samples, {} test samples'.format(len(X_train), len(X_test)))\n",
    "print('---review---')\n",
    "print(X_train[6])\n",
    "print('---label---')\n",
    "print(y_train[6])\n",
    "\n",
    "print('Maximum review length: {}'.format(\n",
    "len(max((X_train + X_test), key=len))))\n",
    "\n",
    "print('Minimum review length: {}'.format(\n",
    "len(min((X_train + X_test), key=len))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8v5j0zHarXU_"
   },
   "source": [
    "Change sequences length in order to be in a same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "3yb2bjr1JIOV",
    "outputId": "f638910b-1c62-495c-807d-27562d0ff6a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape train: (25000, 500) shape test: (25000, 500)\n"
     ]
    }
   ],
   "source": [
    "max_words = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n",
    "\n",
    "print('shape train:',X_train.shape, 'shape test:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Cxr4ZFLjrxhL"
   },
   "source": [
    "Define layers inside the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dnlW8ABhP0Vt"
   },
   "outputs": [],
   "source": [
    "input_seq = Input(shape=(max_words,))\n",
    "embedding_size= 32\n",
    "emb = Embedding(vocabulary_size, embedding_size)(input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "V7Ck7FGfQ6Vc",
    "outputId": "ca79e0d4-70ea-4ece-cf04-0050c22c0e75"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'input_1:0' shape=(None, 500) dtype=float32>"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "w2Ke00CkQt7V",
    "outputId": "361a3a64-ae5d-44d0-8bad-ef915c995f67"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'embedding_1/embedding_lookup/Identity_1:0' shape=(None, 500, 32) dtype=float32>"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 267
    },
    "colab_type": "code",
    "id": "8DtSfbeZHrM2",
    "outputId": "4159f658-3bb2-41a8-8844-d210edbef2b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p1:\n",
      "Tensor(\"lstm_1/transpose_1:0\", shape=(None, 500, 40), dtype=float32)\n",
      "p1:\n",
      "Tensor(\"lstm_2/transpose_1:0\", shape=(None, 500, 20), dtype=float32)\n",
      "p2:\n",
      "Tensor(\"lstm_3/transpose_1:0\", shape=(None, 500, 40), dtype=float32)\n",
      "p2:\n",
      "Tensor(\"lstm_4/transpose_1:0\", shape=(None, 500, 20), dtype=float32)\n",
      "out:\n",
      "Tensor(\"concatenate_1/concat:0\", shape=(None, 500, 40), dtype=float32)\n",
      "out after flatten:\n",
      "Tensor(\"flatten_1/Reshape:0\", shape=(None, None), dtype=float32)\n",
      "final out\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'dense_1/Softmax:0' shape=(None, 1) dtype=float32>"
      ]
     },
     "execution_count": 7,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---------------- path one -------------------------\n",
    "path_1 = LSTM(40, return_sequences= True)(emb)\n",
    "print('p1:')\n",
    "print(path_1)\n",
    "\n",
    "path_1= LSTM(20, return_sequences= True)(path_1)\n",
    "print('p1:')\n",
    "print(path_1)\n",
    "\n",
    "# ---------------- path two -------------------------\n",
    "path_2 = LSTM(40, return_sequences= True)(emb)\n",
    "print('p2:')\n",
    "print(path_2)\n",
    "path_2 = LSTM(20, return_sequences= True)(path_2)\n",
    "print('p2:')\n",
    "print(path_2)\n",
    "\n",
    "# ---------------- concatenating -------------------------\n",
    "outl = Concatenate()([path_1,path_2])\n",
    "print('out:')\n",
    "print(outl)\n",
    "\n",
    "outl = Flatten()(outl)\n",
    "print('out after flatten:')\n",
    "print(outl)\n",
    "\n",
    "# ---------------- final output -------------------------\n",
    "outl = Dense(1, activation='softmax')(outl)\n",
    "print('final out')\n",
    "outl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "colab_type": "code",
    "id": "5Q5aJl2QbSB6",
    "outputId": "7619469e-19f6-4740-ce5a-5354f2a8b0c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 500)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 500, 32)      160000      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 500, 40)      11680       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   (None, 500, 40)      11680       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 500, 20)      4880        lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   (None, 500, 20)      4880        lstm_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 500, 40)      0           lstm_2[0][0]                     \n",
      "                                                                 lstm_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 20000)        0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            20001       flatten_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 213,121\n",
      "Trainable params: 213,121\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model= Model(inputs = input_seq, outputs = outl)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BCSGo_l4r50C"
   },
   "source": [
    "Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "colab_type": "code",
    "id": "ZJ1_bAXVHqxC",
    "outputId": "2595224b-259c-4841-aef4-b91932b5b67d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24488 samples, validate on 512 samples\n",
      "Epoch 1/10\n",
      "24488/24488 [==============================] - 243s 10ms/step - loss: 7.6666 - accuracy: 0.5000 - precision_1: 0.5000 - recall_1: 1.0000 - val_loss: 7.6246 - val_accuracy: 0.5000 - val_precision_1: 0.5000 - val_recall_1: 1.0000\n",
      "Epoch 2/10\n",
      "24488/24488 [==============================] - 239s 10ms/step - loss: 7.6666 - accuracy: 0.5000 - precision_1: 0.5000 - recall_1: 1.0000 - val_loss: 7.6246 - val_accuracy: 0.5000 - val_precision_1: 0.5000 - val_recall_1: 1.0000\n",
      "Epoch 3/10\n",
      "24488/24488 [==============================] - 239s 10ms/step - loss: 7.6666 - accuracy: 0.5000 - precision_1: 0.5000 - recall_1: 1.0000 - val_loss: 7.6246 - val_accuracy: 0.5000 - val_precision_1: 0.5000 - val_recall_1: 1.0000\n",
      "Epoch 4/10\n",
      "24488/24488 [==============================] - 237s 10ms/step - loss: 7.6666 - accuracy: 0.5000 - precision_1: 0.5000 - recall_1: 1.0000 - val_loss: 7.6246 - val_accuracy: 0.5000 - val_precision_1: 0.5000 - val_recall_1: 1.0000\n",
      "Epoch 5/10\n",
      "24488/24488 [==============================] - 239s 10ms/step - loss: 7.6666 - accuracy: 0.5000 - precision_1: 0.5000 - recall_1: 1.0000 - val_loss: 7.6246 - val_accuracy: 0.5000 - val_precision_1: 0.5000 - val_recall_1: 1.0000\n",
      "Epoch 6/10\n",
      "24488/24488 [==============================] - 240s 10ms/step - loss: 7.6666 - accuracy: 0.5000 - precision_1: 0.5000 - recall_1: 1.0000 - val_loss: 7.6246 - val_accuracy: 0.5000 - val_precision_1: 0.5000 - val_recall_1: 1.0000\n",
      "Epoch 7/10\n",
      "24488/24488 [==============================] - 237s 10ms/step - loss: 7.6666 - accuracy: 0.5000 - precision_1: 0.5000 - recall_1: 1.0000 - val_loss: 7.6246 - val_accuracy: 0.5000 - val_precision_1: 0.5000 - val_recall_1: 1.0000\n",
      "Epoch 8/10\n",
      "24488/24488 [==============================] - 242s 10ms/step - loss: 7.6666 - accuracy: 0.5000 - precision_1: 0.5000 - recall_1: 1.0000 - val_loss: 7.6246 - val_accuracy: 0.5000 - val_precision_1: 0.5000 - val_recall_1: 1.0000\n",
      "Epoch 9/10\n",
      "24488/24488 [==============================] - 238s 10ms/step - loss: 7.6666 - accuracy: 0.5000 - precision_1: 0.5000 - recall_1: 1.0000 - val_loss: 7.6246 - val_accuracy: 0.5000 - val_precision_1: 0.5000 - val_recall_1: 1.0000\n",
      "Epoch 10/10\n",
      "24488/24488 [==============================] - 239s 10ms/step - loss: 7.6666 - accuracy: 0.5000 - precision_1: 0.5000 - recall_1: 1.0000 - val_loss: 7.6246 - val_accuracy: 0.5000 - val_precision_1: 0.5000 - val_recall_1: 1.0000\n",
      "Test accuracy: 0.5\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', \n",
    "             optimizer='adam', \n",
    "             metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "\t\t\t \n",
    "batch_size = 512\n",
    "num_epochs = 10\n",
    "X_valid, y_valid = X_train[:batch_size], y_train[:batch_size]\n",
    "X_train2, y_train2 = X_train[batch_size:], y_train[batch_size:]\n",
    "model.fit(X_train2, y_train2, validation_data=(X_valid, y_valid), batch_size=batch_size, epochs=num_epochs)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "i_4UbCBk5M3M",
    "outputId": "5e579f17-f632-49f6-935b-3ec691ec6cf5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 50.0 \n",
      " precision: 50.0 \n",
      " recall: 100.0\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy:\", scores[1]*100 , \"\\n precision:\", scores[2]*100, \"\\n recall:\", scores[3]*100)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DL_5_LSTM_update3_10epoch_inception and stacked-softmax.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
