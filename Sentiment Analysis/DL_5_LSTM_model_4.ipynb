{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_5_LSTM_model4_update3_10epoch_inception and stacked-sigmoid.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vMuqtwz6HPFu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "126ae790-538a-4834-e650-d1594899bea4"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "import keras\n",
        "import keras.backend as K\n",
        "from keras.layers import Flatten, Concatenate, Input , Embedding, LSTM, Dense, Dropout\n",
        "from keras.datasets import imdb\n",
        "from keras.preprocessing import sequence\n",
        "from keras import Sequential\n",
        "from keras.models import Model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yc5KvFPbqjr1",
        "colab_type": "text"
      },
      "source": [
        "Load IMDB dataset from keras.datasets.\n",
        "\n",
        "\"This is a dataset of 25,000 movies reviews from IMDB, labeled by sentiment (positive/negative).\" [[1]](https://keras.io/api/datasets/imdb/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhVWGXDoHXmQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "6e16f64a-6d2f-47bb-fb4c-074f468d8b40"
      },
      "source": [
        "vocabulary_size = 5000\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocabulary_size, skip_top=127, oov_char= 00 )\n",
        "\n",
        "print('Loaded dataset with {} training samples, {} test samples'.format(len(X_train), len(X_test)))\n",
        "print('---review---')\n",
        "print(X_train[6])\n",
        "print('---label---')\n",
        "print(y_train[6])\n",
        "\n",
        "print('Maximum review length: {}'.format(\n",
        "len(max((X_train + X_test), key=len))))\n",
        "\n",
        "print('Minimum review length: {}'.format(\n",
        "len(min((X_train + X_test), key=len))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/text-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 2s 0us/step\n",
            "Loaded dataset with 25000 training samples, 25000 test samples\n",
            "---review---\n",
            "[0, 0, 365, 1234, 0, 1156, 354, 0, 0, 0, 0, 0, 1016, 0, 0, 356, 0, 0, 1349, 500, 746, 0, 200, 0, 4132, 0, 0, 0, 1117, 1831, 0, 0, 4831, 0, 0, 0, 4183, 0, 369, 0, 215, 1345, 143, 0, 0, 1838, 0, 1974, 0, 0, 0, 257, 0, 0, 486, 0, 0, 0, 0, 0, 271, 0, 196, 0, 949, 4121, 0, 0, 0, 0, 2212, 2436, 819, 0, 0, 0, 0, 180, 0, 227, 0, 0, 2494, 0, 0, 423, 0, 168, 0, 0, 0, 0, 0, 665, 0, 270, 0, 0, 0, 197, 0, 161, 0, 0, 0, 0, 0, 0, 419, 665, 0, 0, 0, 0, 0, 0, 2084, 0, 4773, 0, 0, 0, 1901]\n",
            "---label---\n",
            "1\n",
            "Maximum review length: 2697\n",
            "Minimum review length: 70\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8v5j0zHarXU_",
        "colab_type": "text"
      },
      "source": [
        "Change sequences length in order to be in a same size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3yb2bjr1JIOV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "61da88f0-eec8-448a-a22f-42e0212ca9b0"
      },
      "source": [
        "max_words = 500\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n",
        "\n",
        "print('shape train:',X_train.shape, 'shape test:', X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape train: (25000, 500) shape test: (25000, 500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cxr4ZFLjrxhL",
        "colab_type": "text"
      },
      "source": [
        "Define layers inside the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnlW8ABhP0Vt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_seq = Input(shape=(max_words,))\n",
        "embedding_size= 32\n",
        "emb = Embedding(vocabulary_size, embedding_size)(input_seq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7Ck7FGfQ6Vc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "914585a2-6ba9-4f9b-cb44-19b2927f8a94"
      },
      "source": [
        "input_seq"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'input_1:0' shape=(None, 500) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2Ke00CkQt7V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "771ab37c-b849-43b9-d0fd-c06bb2d27c38"
      },
      "source": [
        "emb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'embedding_1/embedding_lookup/Identity_1:0' shape=(None, 500, 32) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DtSfbeZHrM2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 267
        },
        "outputId": "3b345b69-aa89-493c-a846-d9fbc78bcb42"
      },
      "source": [
        "# ---------------- path one -------------------------\n",
        "path_1 = LSTM(40, return_sequences= True)(emb)\n",
        "print('p1:')\n",
        "print(path_1)\n",
        "\n",
        "path_1= LSTM(20, return_sequences= True)(path_1)\n",
        "print('p1:')\n",
        "print(path_1)\n",
        "\n",
        "# ---------------- path two -------------------------\n",
        "path_2 = LSTM(60, return_sequences= True)(emb)\n",
        "print('p2:')\n",
        "print(path_2)\n",
        "path_2 = LSTM(40, return_sequences= True)(path_2)\n",
        "print('p2:')\n",
        "print(path_2)\n",
        "\n",
        "# ---------------- concatenating -------------------------\n",
        "outl = Concatenate()([path_1,path_2])\n",
        "print('out:')\n",
        "print(outl)\n",
        "\n",
        "outl = Flatten()(outl)\n",
        "print('out after flatten:')\n",
        "print(outl)\n",
        "\n",
        "# ---------------- final output -------------------------\n",
        "outl = Dense(1, activation='sigmoid')(outl)\n",
        "print('final out')\n",
        "outl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "p1:\n",
            "Tensor(\"lstm_1/transpose_1:0\", shape=(None, 500, 40), dtype=float32)\n",
            "p1:\n",
            "Tensor(\"lstm_2/transpose_1:0\", shape=(None, 500, 20), dtype=float32)\n",
            "p2:\n",
            "Tensor(\"lstm_3/transpose_1:0\", shape=(None, 500, 60), dtype=float32)\n",
            "p2:\n",
            "Tensor(\"lstm_4/transpose_1:0\", shape=(None, 500, 40), dtype=float32)\n",
            "out:\n",
            "Tensor(\"concatenate_1/concat:0\", shape=(None, 500, 60), dtype=float32)\n",
            "out after flatten:\n",
            "Tensor(\"flatten_1/Reshape:0\", shape=(None, None), dtype=float32)\n",
            "final out\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor 'dense_1/Sigmoid:0' shape=(None, 1) dtype=float32>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Q5aJl2QbSB6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "outputId": "7eb0f221-39df-4dc5-b6b9-afb418d13021"
      },
      "source": [
        "model= Model(inputs = input_seq, outputs = outl)\n",
        "print(model.summary())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 500)          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 500, 32)      160000      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   (None, 500, 40)      11680       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   (None, 500, 60)      22320       embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   (None, 500, 20)      4880        lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_4 (LSTM)                   (None, 500, 40)      16160       lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 500, 60)      0           lstm_2[0][0]                     \n",
            "                                                                 lstm_4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 30000)        0           concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1)            30001       flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 245,041\n",
            "Trainable params: 245,041\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCSGo_l4r50C",
        "colab_type": "text"
      },
      "source": [
        "Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJ1_bAXVHqxC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "outputId": "43803970-4ef1-48b6-c72d-e3e41197f759"
      },
      "source": [
        "model.compile(loss='binary_crossentropy', \n",
        "             optimizer='adam', \n",
        "             metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()])\n",
        "\t\t\t \n",
        "batch_size = 512\n",
        "num_epochs = 10\n",
        "X_valid, y_valid = X_train[:batch_size], y_train[:batch_size]\n",
        "X_train2, y_train2 = X_train[batch_size:], y_train[batch_size:]\n",
        "model.fit(X_train2, y_train2, validation_data=(X_valid, y_valid), batch_size=batch_size, epochs=num_epochs)\n",
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test accuracy:', scores[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 24488 samples, validate on 512 samples\n",
            "Epoch 1/10\n",
            "24488/24488 [==============================] - 249s 10ms/step - loss: 0.6358 - accuracy: 0.6180 - precision_1: 0.6138 - recall_1: 0.6365 - val_loss: 0.3915 - val_accuracy: 0.8008 - val_precision_1: 0.7984 - val_recall_1: 0.8047\n",
            "Epoch 2/10\n",
            "24488/24488 [==============================] - 246s 10ms/step - loss: 0.3285 - accuracy: 0.8603 - precision_1: 0.8564 - recall_1: 0.8658 - val_loss: 0.2912 - val_accuracy: 0.8770 - val_precision_1: 0.8669 - val_recall_1: 0.8906\n",
            "Epoch 3/10\n",
            "24488/24488 [==============================] - 246s 10ms/step - loss: 0.2710 - accuracy: 0.8879 - precision_1: 0.8837 - recall_1: 0.8933 - val_loss: 0.2930 - val_accuracy: 0.8789 - val_precision_1: 0.8647 - val_recall_1: 0.8984\n",
            "Epoch 4/10\n",
            "24488/24488 [==============================] - 246s 10ms/step - loss: 0.2384 - accuracy: 0.9028 - precision_1: 0.8997 - recall_1: 0.9066 - val_loss: 0.2987 - val_accuracy: 0.8867 - val_precision_1: 0.8613 - val_recall_1: 0.9219\n",
            "Epoch 5/10\n",
            "24488/24488 [==============================] - 241s 10ms/step - loss: 0.2036 - accuracy: 0.9181 - precision_1: 0.9138 - recall_1: 0.9233 - val_loss: 0.3031 - val_accuracy: 0.8828 - val_precision_1: 0.8657 - val_recall_1: 0.9062\n",
            "Epoch 6/10\n",
            "24488/24488 [==============================] - 242s 10ms/step - loss: 0.1898 - accuracy: 0.9242 - precision_1: 0.9215 - recall_1: 0.9275 - val_loss: 0.3960 - val_accuracy: 0.8242 - val_precision_1: 0.9235 - val_recall_1: 0.7070\n",
            "Epoch 7/10\n",
            "24488/24488 [==============================] - 240s 10ms/step - loss: 0.1729 - accuracy: 0.9318 - precision_1: 0.9312 - recall_1: 0.9325 - val_loss: 0.3518 - val_accuracy: 0.8691 - val_precision_1: 0.8436 - val_recall_1: 0.9062\n",
            "Epoch 8/10\n",
            "24488/24488 [==============================] - 242s 10ms/step - loss: 0.1504 - accuracy: 0.9431 - precision_1: 0.9409 - recall_1: 0.9456 - val_loss: 0.4040 - val_accuracy: 0.8477 - val_precision_1: 0.9238 - val_recall_1: 0.7578\n",
            "Epoch 9/10\n",
            "24488/24488 [==============================] - 251s 10ms/step - loss: 0.1206 - accuracy: 0.9554 - precision_1: 0.9554 - recall_1: 0.9553 - val_loss: 0.4303 - val_accuracy: 0.8711 - val_precision_1: 0.8598 - val_recall_1: 0.8867\n",
            "Epoch 10/10\n",
            "24488/24488 [==============================] - 252s 10ms/step - loss: 0.1043 - accuracy: 0.9599 - precision_1: 0.9600 - recall_1: 0.9597 - val_loss: 0.4776 - val_accuracy: 0.8613 - val_precision_1: 0.8745 - val_recall_1: 0.8438\n",
            "Test accuracy: 0.8349999785423279\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_4UbCBk5M3M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "387ce603-b510-4eb9-fbee-fe10c3e8f5e8"
      },
      "source": [
        "print(\"accuracy:\", scores[1]*100 , \"\\n precision:\", scores[2]*100, \"\\n recall:\", scores[3]*100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 83.49999785423279 \n",
            " precision: 82.46878981590271 \n",
            " recall: 85.08800268173218\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}