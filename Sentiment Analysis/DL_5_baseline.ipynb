{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "JjJGUtIoCdqV",
    "outputId": "2ff498df-d694-4a7a-fc6b-71398954c3e9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "colab_type": "code",
    "id": "LLJz99vxB_sE",
    "outputId": "366e66ee-b43b-454f-d604-0cd0a854c1b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 25000 training samples, 25000 test samples\n",
      "---review---\n",
      "[1, 2, 365, 1234, 5, 1156, 354, 11, 14, 2, 2, 7, 1016, 2, 2, 356, 44, 4, 1349, 500, 746, 5, 200, 4, 4132, 11, 2, 2, 1117, 1831, 2, 5, 4831, 26, 6, 2, 4183, 17, 369, 37, 215, 1345, 143, 2, 5, 1838, 8, 1974, 15, 36, 119, 257, 85, 52, 486, 9, 6, 2, 2, 63, 271, 6, 196, 96, 949, 4121, 4, 2, 7, 4, 2212, 2436, 819, 63, 47, 77, 2, 180, 6, 227, 11, 94, 2494, 2, 13, 423, 4, 168, 7, 4, 22, 5, 89, 665, 71, 270, 56, 5, 13, 197, 12, 161, 2, 99, 76, 23, 2, 7, 419, 665, 40, 91, 85, 108, 7, 4, 2084, 5, 4773, 81, 55, 52, 1901]\n",
      "---label---\n",
      "1\n",
      "Maximum review length: 2697\n",
      "Minimum review length: 14\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = vocabulary_size)\n",
    "print('Loaded dataset with {} training samples, {} test samples'.format(len(X_train), len(X_test)))\n",
    "print('---review---')\n",
    "print(X_train[6])\n",
    "print('---label---')\n",
    "print(y_train[6])\n",
    "\n",
    "\n",
    "print('Maximum review length: {}'.format(\n",
    "len(max((X_train + X_test), key=len))))\n",
    "\n",
    "print('Minimum review length: {}'.format(\n",
    "len(min((X_test + X_test), key=len))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "id": "SNagN_sMCme-",
    "outputId": "0f9ad013-4625-47df-df9e-fea3bc97e437"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 500, 32)           160000    \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 70)                28840     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 71        \n",
      "=================================================================\n",
      "Total params: 188,911\n",
      "Trainable params: 188,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "max_words = 500\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "embedding_size=32\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
    "model.add(LSTM(70))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 448
    },
    "colab_type": "code",
    "id": "8Bu0mZ5sCpHa",
    "outputId": "c009060f-3073-47b3-98df-4fe1061f84dd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24936 samples, validate on 64 samples\n",
      "Epoch 1/10\n",
      "24936/24936 [==============================] - 321s 13ms/step - loss: 0.4520 - accuracy: 0.7855 - precision_3: 0.8105 - recall_2: 0.7457 - val_loss: 0.2234 - val_accuracy: 0.9375 - val_precision_3: 0.8889 - val_recall_2: 0.9600\n",
      "Epoch 2/10\n",
      "24936/24936 [==============================] - 323s 13ms/step - loss: 0.2742 - accuracy: 0.8920 - precision_3: 0.8941 - recall_2: 0.8894 - val_loss: 0.2442 - val_accuracy: 0.8906 - val_precision_3: 0.8462 - val_recall_2: 0.8800\n",
      "Epoch 3/10\n",
      "24936/24936 [==============================] - 324s 13ms/step - loss: 0.2402 - accuracy: 0.9063 - precision_3: 0.9065 - recall_2: 0.9062 - val_loss: 0.2854 - val_accuracy: 0.9062 - val_precision_3: 0.9524 - val_recall_2: 0.8000\n",
      "Epoch 4/10\n",
      "24936/24936 [==============================] - 323s 13ms/step - loss: 0.2345 - accuracy: 0.9067 - precision_3: 0.9147 - recall_2: 0.8972 - val_loss: 0.3111 - val_accuracy: 0.8906 - val_precision_3: 0.8462 - val_recall_2: 0.8800\n",
      "Epoch 5/10\n",
      "24936/24936 [==============================] - 324s 13ms/step - loss: 0.1960 - accuracy: 0.9241 - precision_3: 0.9226 - recall_2: 0.9259 - val_loss: 0.2627 - val_accuracy: 0.8906 - val_precision_3: 0.8750 - val_recall_2: 0.8400\n",
      "Epoch 6/10\n",
      "24936/24936 [==============================] - 321s 13ms/step - loss: 0.1842 - accuracy: 0.9296 - precision_3: 0.9325 - recall_2: 0.9263 - val_loss: 0.2696 - val_accuracy: 0.9062 - val_precision_3: 0.8800 - val_recall_2: 0.8800\n",
      "Epoch 7/10\n",
      "24936/24936 [==============================] - 320s 13ms/step - loss: 0.1565 - accuracy: 0.9414 - precision_3: 0.9430 - recall_2: 0.9396 - val_loss: 0.3117 - val_accuracy: 0.8906 - val_precision_3: 0.8214 - val_recall_2: 0.9200\n",
      "Epoch 8/10\n",
      "24936/24936 [==============================] - 321s 13ms/step - loss: 0.1606 - accuracy: 0.9392 - precision_3: 0.9426 - recall_2: 0.9354 - val_loss: 0.2217 - val_accuracy: 0.9062 - val_precision_3: 0.8276 - val_recall_2: 0.9600\n",
      "Epoch 9/10\n",
      "24936/24936 [==============================] - 320s 13ms/step - loss: 0.1668 - accuracy: 0.9356 - precision_3: 0.9307 - recall_2: 0.9413 - val_loss: 0.2214 - val_accuracy: 0.9062 - val_precision_3: 0.8276 - val_recall_2: 0.9600\n",
      "Epoch 10/10\n",
      "24936/24936 [==============================] - 319s 13ms/step - loss: 0.1288 - accuracy: 0.9524 - precision_3: 0.9517 - recall_2: 0.9533 - val_loss: 0.2011 - val_accuracy: 0.9219 - val_precision_3: 0.8571 - val_recall_2: 0.9600\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', \n",
    "             optimizer='adam', \n",
    "             metrics=['accuracy', keras.metrics.Precision(), keras.metrics.Recall()])\n",
    "\t\t\t \n",
    "batch_size = 64\n",
    "num_epochs = 10\n",
    "X_valid, y_valid = X_train[:batch_size], y_train[:batch_size]\n",
    "X_train2, y_train2 = X_train[batch_size:], y_train[batch_size:]\n",
    "model.fit(X_train2, y_train2, validation_data=(X_valid, y_valid), batch_size=batch_size, epochs=num_epochs)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 71
    },
    "colab_type": "code",
    "id": "ZWXRlo21DFNs",
    "outputId": "97c53f9c-e85a-4e04-f7dc-b4153260c00b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 86.39600276947021 \n",
      " precision: 84.4998836517334 \n",
      " recall: 89.14399743080139\n"
     ]
    }
   ],
   "source": [
    "print(\"accuracy:\", scores[1]*100 , \"\\n precision:\", scores[2]*100, \"\\n recall:\", scores[3]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E10NUZ-eC2p6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DL_5_baseline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
