{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "JjCqSnU4DCav",
    "outputId": "907c878b-bb80-4201-fb65-a75d65c797d2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.layers import Flatten\n",
    "from keras.datasets import imdb\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "from keras import Sequential\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9DxOw5HOFZZi"
   },
   "source": [
    "Cheking the index of a word in dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "nCX9bJEdD_jg",
    "outputId": "7f9702fa-d6b1-40df-99c0-2ea849f75b5b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4822"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.datasets.imdb.get_word_index(path=\"imdb_word_index.json\")['hello']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gR1Km-evFtlf"
   },
   "source": [
    "As you can see, the stop words are also included inside this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "EJCTK1qfFjBS",
    "outputId": "ced68f07-3e4b-4cf0-f44d-24d589d6b2b7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.datasets.imdb.get_word_index(path=\"imdb_word_index.json\")['the']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "z31-sL77R0tE"
   },
   "source": [
    "***Note:*** The words have been added to the list by considering the frequencies. For example, the most frequent word in English is \"the\" which has the first index in vocabulary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "miHPuFdFGRIG"
   },
   "source": [
    "How can we ***remove*** these frequent words? \n",
    "\n",
    "By skipping most frequent words using skip_top!\n",
    "\n",
    "\"skip_top: skip the top N most frequently occurring words (which may not be informative). These words will appear as oov_char value in the dataset. Defaults to 0, so no words are skipped.\",[[1]](https://keras.io/api/datasets/reuters/)\n",
    "\n",
    "Here, I supposed that we have one hundred and twenty-seven stop words in this dataset. Therefore, I removed one hundred and twenty-seven frequent words in the vocab and replaced them with \"removed\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "colab_type": "code",
    "id": "ywBDNb9nF_dT",
    "outputId": "b1d7955b-f656-43c7-d0f5-e20f3582383e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 25000 training samples, 25000 test samples\n",
      "---review---\n",
      "[0, 0, 365, 1234, 0, 1156, 354, 0, 0, 0, 0, 0, 1016, 0, 0, 356, 0, 0, 1349, 500, 746, 0, 200, 0, 4132, 0, 0, 0, 1117, 1831, 0, 0, 4831, 0, 0, 0, 4183, 0, 369, 0, 215, 1345, 143, 0, 0, 1838, 0, 1974, 0, 0, 0, 257, 0, 0, 486, 0, 0, 0, 0, 0, 271, 0, 196, 0, 949, 4121, 0, 0, 0, 0, 2212, 2436, 819, 0, 0, 0, 0, 180, 0, 227, 0, 0, 2494, 0, 0, 423, 0, 168, 0, 0, 0, 0, 0, 665, 0, 270, 0, 0, 0, 197, 0, 161, 0, 0, 0, 0, 0, 0, 419, 665, 0, 0, 0, 0, 0, 0, 2084, 0, 4773, 0, 0, 0, 1901]\n",
      "---label---\n",
      "1\n",
      "Maximum review length: 2697\n",
      "Minimum review length: 70\n"
     ]
    }
   ],
   "source": [
    "vocabulary_size = 5000\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocabulary_size, skip_top=127, oov_char= 00 )\n",
    "\n",
    "print('Loaded dataset with {} training samples, {} test samples'.format(len(X_train), len(X_test)))\n",
    "print('---review---')\n",
    "print(X_train[6])\n",
    "print('---label---')\n",
    "print(y_train[6])\n",
    "\n",
    "print('Maximum review length: {}'.format(\n",
    "len(max((X_train + X_test), key=len))))\n",
    "\n",
    "print('Minimum review length: {}'.format(\n",
    "len(min((X_train + X_test), key=len))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vUD58JRtI7lp"
   },
   "outputs": [],
   "source": [
    "# simple check \n",
    "for i in range(len(X_train)):\n",
    "  for j in range(len(X_train[i])):\n",
    "    if X_train[i][j]==126:\n",
    "      print(i, j , '127th stop word did not removed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "8mRoALbuTrzg",
    "outputId": "0e9afc46-abd0-4b31-a5f3-40bba2949182"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape train: (25000, 2494) shape test: (25000, 2315)\n"
     ]
    }
   ],
   "source": [
    "#max_words = 500\n",
    "#X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "#X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train)\n",
    "X_test = sequence.pad_sequences(X_test)\n",
    "print('shape train:',X_train.shape, 'shape test:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "D-f9-azFYzZk",
    "outputId": "19c30bd3-4a76-43cd-b25b-354dee9682e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape train: (25000, 2315) shape test: (25000, 2315)\n"
     ]
    }
   ],
   "source": [
    "max_words = 2315\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=max_words)\n",
    "\n",
    "print('shape train:',X_train.shape, 'shape test:', X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 285
    },
    "colab_type": "code",
    "id": "rdIkqYlKWQcM",
    "outputId": "d86bcd39-66e7-4948-c2d8-6ea59eddc4b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 2315, 32)          160000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 70)                28840     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 71        \n",
      "=================================================================\n",
      "Total params: 188,911\n",
      "Trainable params: 188,911\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embedding_size=32\n",
    "model=Sequential()\n",
    "model.add(Embedding(vocabulary_size, embedding_size, input_length=X_train.shape[1]))\n",
    "model.add(LSTM(70))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "colab_type": "code",
    "id": "OBP4fvpRV8c_",
    "outputId": "d3321489-5e02-4d63-f056-7e84eb013965",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 24744 samples, validate on 256 samples\n",
      "Epoch 1/10\n",
      "24744/24744 [==============================] - 357s 14ms/step - loss: 0.6590 - accuracy: 0.6365 - val_loss: 0.6510 - val_accuracy: 0.5742\n",
      "Epoch 2/10\n",
      "24744/24744 [==============================] - 349s 14ms/step - loss: 0.4651 - accuracy: 0.7728 - val_loss: 0.3259 - val_accuracy: 0.8789\n",
      "Epoch 3/10\n",
      "24744/24744 [==============================] - 350s 14ms/step - loss: 0.3064 - accuracy: 0.8724 - val_loss: 0.2721 - val_accuracy: 0.8828\n",
      "Epoch 4/10\n",
      "24744/24744 [==============================] - 348s 14ms/step - loss: 0.2615 - accuracy: 0.8963 - val_loss: 0.2791 - val_accuracy: 0.8750\n",
      "Epoch 5/10\n",
      "24744/24744 [==============================] - 351s 14ms/step - loss: 0.2860 - accuracy: 0.8868 - val_loss: 0.3313 - val_accuracy: 0.8672\n",
      "Epoch 6/10\n",
      "24744/24744 [==============================] - 353s 14ms/step - loss: 0.2381 - accuracy: 0.9080 - val_loss: 0.2451 - val_accuracy: 0.9062\n",
      "Epoch 7/10\n",
      "24744/24744 [==============================] - 371s 15ms/step - loss: 0.2153 - accuracy: 0.9191 - val_loss: 0.3344 - val_accuracy: 0.8594\n",
      "Epoch 8/10\n",
      "24744/24744 [==============================] - 351s 14ms/step - loss: 0.2122 - accuracy: 0.9186 - val_loss: 0.2587 - val_accuracy: 0.8984\n",
      "Epoch 9/10\n",
      "24744/24744 [==============================] - 348s 14ms/step - loss: 0.1839 - accuracy: 0.9308 - val_loss: 0.2605 - val_accuracy: 0.8867\n",
      "Epoch 10/10\n",
      "24744/24744 [==============================] - 350s 14ms/step - loss: 0.1721 - accuracy: 0.9375 - val_loss: 0.2793 - val_accuracy: 0.8867\n",
      "Test accuracy: 0.8587999939918518\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', \n",
    "             optimizer='adam', \n",
    "             metrics=['accuracy'])\n",
    "\t\t\t \n",
    "batch_size = 256\n",
    "num_epochs = 10\n",
    "X_valid, y_valid = X_train[:batch_size], y_train[:batch_size]\n",
    "X_train2, y_train2 = X_train[batch_size:], y_train[batch_size:]\n",
    "model.fit(X_train2, y_train2, validation_data=(X_valid, y_valid), batch_size=batch_size, epochs=num_epochs)\n",
    "scores = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test accuracy:', scores[1])"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DL_5_LSTM_update1_10epoch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
